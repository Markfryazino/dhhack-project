{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "import pymystem3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_group(mypath):\n",
    "    files = []\n",
    "    stem = pymystem3.Mystem()\n",
    "    \n",
    "    for r, d, f in os.walk(mypath):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "        \n",
    "    docs = []\n",
    "    full = ''\n",
    "    wordset = set()\n",
    "    \n",
    "    for filepath in files:\n",
    "        corpus = []\n",
    "        with open(filepath) as file:\n",
    "            for line in file:\n",
    "                corpus.append(line)\n",
    "        corpus = [el for el in corpus if el != '\\n']\n",
    "        \n",
    "        corpus = [re.sub(r'[^\\w\\s]','',el)[:-1] for el in corpus]\n",
    "        \n",
    "        for el in corpus:\n",
    "            words = el.lower()\n",
    "            proc = stem.lemmatize(words)\n",
    "            proc = [w for w in proc if (w != ' ') and (w != '\\n')]\n",
    "            docs.append(proc)\n",
    "            \n",
    "            for word in proc:\n",
    "                full += ' ' + word\n",
    "                wordset.add(word)\n",
    "        print(filepath)\n",
    "\n",
    "    return docs, wordset, full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./books/classic/jivago.txt\n",
      "./books/classic/warandpeace.txt\n",
      "./books/classic/govardtales.txt\n",
      "./books/classic/brotherskaramasovi.txt\n",
      "./books/classic/atthemountainsofmadness.txt\n",
      "./books/classic/annakarenina.txt\n",
      "./books/classic/oblomov.txt\n",
      "./books/classic/idiot.txt\n",
      "./books/classic/journeytomoscow.txt\n",
      "./books/classic/onegin.txt\n",
      "./books/classic/ktulhu_demo.txt\n",
      "./books/classic/masterandmargaret.txt\n",
      "./books/trash/lullaby.txt\n",
      "./books/trash/survivor.txt\n",
      "./books/trash/chapaev_demo.txt\n",
      "./books/trash/Pelevin.txt\n",
      "./books/trash/rastamans.txt\n",
      "./books/trash/oneflewover.txt\n",
      "./books/trash/chapaevandvoid.txt\n",
      "./books/trash/pulpfiction.txt\n",
      "./books/trash/mitiki.txt\n",
      "./books/trash/messenger.txt\n",
      "./books/trash/pelevintales.txt\n",
      "./books/trash/choke.txt\n",
      "./books/trash/fightclub.txt\n"
     ]
    }
   ],
   "source": [
    "docs_c, wordset_c, full_c = prepare_group('./books/classic')\n",
    "docs_t, wordset_t, full_t = prepare_group('./books/trash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = docs_c + docs_t\n",
    "fulls = [full_c, full_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(texts, size=100, iter=5, workers=8, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no2', 0.9041868448257446),\n",
       " ('джа', 0.9028873443603516),\n",
       " ('дьякон', 0.8989834785461426),\n",
       " ('роял', 0.8938823342323303),\n",
       " ('уау', 0.8937105536460876),\n",
       " ('вишь', 0.8935484290122986),\n",
       " ('герло', 0.8911558389663696),\n",
       " ('чувак', 0.8910033702850342),\n",
       " ('ждемто', 0.890834629535675),\n",
       " ('зк', 0.8892228603363037)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('растаман')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "tfidf = vec.fit_transform(fulls)\n",
    "npidf = tfidf.toarray()\n",
    "fnames = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#неправильно\n",
    "def logic(string):\n",
    "    for word in string.split():\n",
    "        try:\n",
    "            index = fnames.index(word)\n",
    "            idf = npidf[:, index]\n",
    "            if (idf[1] > 100 * idf[0]) or (idf[2] > 100 * idf[0]):\n",
    "                best = '0'\n",
    "                best_res = -100\n",
    "                for gword in sets[0]:\n",
    "                    score = model.wv.similarity(word, gword)\n",
    "                    if score > best_res:\n",
    "                        best_res = score\n",
    "                        best = gword\n",
    "                print(word, ' ---> ', best)\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
