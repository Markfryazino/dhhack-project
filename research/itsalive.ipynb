{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "import pymystem3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_group(mypath):\n",
    "    files = []\n",
    "    stem = pymystem3.Mystem()\n",
    "    \n",
    "    for r, d, f in os.walk(mypath):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "        \n",
    "    docs = []\n",
    "    full = ''\n",
    "    wordset = set()\n",
    "    \n",
    "    for filepath in files:\n",
    "        corpus = []\n",
    "        with open(filepath) as file:\n",
    "            for line in file:\n",
    "                corpus.append(line)\n",
    "        corpus = [el for el in corpus if el != '\\n']\n",
    "        \n",
    "        corpus = [re.sub(r'[^\\w\\s]','',el)[:-1] for el in corpus]\n",
    "        \n",
    "        for el in corpus:\n",
    "            words = el.lower()\n",
    "            proc = stem.lemmatize(words)\n",
    "            proc = [w for w in proc if (w.strip() != '') and (w != '\\n')]\n",
    "            docs.append(proc)\n",
    "            \n",
    "            for word in proc:\n",
    "                full += ' ' + word\n",
    "                wordset.add(word)\n",
    "        print(filepath)\n",
    "\n",
    "    return docs, wordset, full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./books/classic/jivago.txt\n",
      "./books/classic/warandpeace.txt\n",
      "./books/classic/govardtales.txt\n",
      "./books/classic/brotherskaramasovi.txt\n",
      "./books/classic/atthemountainsofmadness.txt\n",
      "./books/classic/annakarenina.txt\n",
      "./books/classic/oblomov.txt\n",
      "./books/classic/idiot.txt\n",
      "./books/classic/journeytomoscow.txt\n",
      "./books/classic/onegin.txt\n",
      "./books/classic/ktulhu_demo.txt\n",
      "./books/classic/masterandmargaret.txt\n",
      "./books/trash/lullaby.txt\n",
      "./books/trash/survivor.txt\n",
      "./books/trash/fameless.txt\n",
      "./books/trash/chapaev_demo.txt\n",
      "./books/trash/Pelevin.txt\n",
      "./books/trash/gruz200.txt\n",
      "./books/trash/rastamans.txt\n",
      "./books/trash/oneflewover.txt\n",
      "./books/trash/chapaevandvoid.txt\n",
      "./books/trash/dogma.txt\n",
      "./books/trash/snatch.txt\n",
      "./books/trash/trainspotting.txt\n",
      "./books/trash/brat.txt\n",
      "./books/trash/pulpfiction.txt\n",
      "./books/trash/mitiki.txt\n",
      "./books/trash/messenger.txt\n",
      "./books/trash/reservoirdogs.txt\n",
      "./books/trash/pelevintales.txt\n",
      "./books/trash/choke.txt\n",
      "./books/trash/piratesofthe.txt\n",
      "./books/trash/fightclub.txt\n"
     ]
    }
   ],
   "source": [
    "docs_c, wordset_c, full_c = prepare_group('./books/classic')\n",
    "docs_t, wordset_t, full_t = prepare_group('./books/trash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = docs_c + docs_t\n",
    "fulls = [full_c, full_t]\n",
    "sets = [wordset_c, wordset_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(texts, size=100, iter=10, workers=8, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(texts, size=100, iter=5, workers=8, min_count=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дерьмо', 0.8320658206939697),\n",
       " ('стих', 0.8217606544494629),\n",
       " ('неприятность', 0.821404755115509),\n",
       " ('мировой', 0.8191081881523132),\n",
       " ('ритуал', 0.8183972835540771),\n",
       " ('способ', 0.817700982093811),\n",
       " ('статус', 0.8173060417175293),\n",
       " ('барсик', 0.8147743940353394),\n",
       " ('санкция', 0.8146173357963562),\n",
       " ('зависимость', 0.8144347667694092)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('фигня')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.37722147e-06, 1.66050262e-03])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'дерьмо'\n",
    "index = fnames.index(word)\n",
    "idf = npidf[:, index]\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "tfidf = vec.fit_transform(fulls)\n",
    "npidf = tfidf.toarray()\n",
    "fnames = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_by_tfidf(fnames, tfidf, word):\n",
    "    try:\n",
    "        index = fnames.index(word)\n",
    "        idf = npidf[:, index]\n",
    "        return idf[1] > 100 * idf[0]\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic(string):\n",
    "    stem = pymystem3.Mystem()\n",
    "    \n",
    "    for word in stem.lemmatize(string):\n",
    "        if word.strip() == '':\n",
    "            continue\n",
    "        try:\n",
    "            if choose_by_tfidf(fnames, tfidf, word):\n",
    "                best = '0'\n",
    "                best_res = -100\n",
    "                for gword in sets[0]:\n",
    "                    score = model.wv.similarity(word, gword)\n",
    "                    if score > best_res:\n",
    "                        best_res = score\n",
    "                        best = gword\n",
    "                print(word, ' ---> ', best)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "фигня  --->  дерьмо\n"
     ]
    }
   ],
   "source": [
    "test = 'фигня'\n",
    "logic(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_cos(word, sets, model):\n",
    "    best = '0'\n",
    "    best_res = -100\n",
    "    for gword in sets[0]:\n",
    "        score = model.wv.similarity(word, gword)\n",
    "        if score > best_res:\n",
    "            best_res = score\n",
    "            best = gword\n",
    "    return best, best_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(string, model, texts, fulls, sets, fnames, tfidf):\n",
    "    res = []\n",
    "    stem = pymystem3.Mystem()\n",
    "    proc = stem.lemmatize(string)\n",
    "    corpus = [re.sub(r'[^\\w\\s]','',el) for el in proc]\n",
    "    corpus = [el for el in corpus if el.strip() != '']\n",
    "    \n",
    "    for word in corpus:\n",
    "        if choose_by_tfidf(fnames, tfidf, word):\n",
    "            chose, pos = select_by_cos(word, sets, model)\n",
    "            res.append([word, chose, pos])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['вася', 'я', 'тут', 'такой', 'блин', 'придумывать']\n"
     ]
    }
   ],
   "source": [
    "production('Вася! я тут такое, блин, придумал', model, texts, fulls, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мимо', 0.013590944),\n",
       " ('ко', 0.00476735),\n",
       " ('домой', 0.003569626),\n",
       " ('куда', 0.0035491132),\n",
       " ('гулять', 0.0034510256),\n",
       " ('улица', 0.0033766152),\n",
       " ('далеко', 0.0026232267),\n",
       " ('отсюда', 0.0024589528),\n",
       " ('пешком', 0.0020692933),\n",
       " ('туда', 0.0019615763)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word(['я', 'идти', 'дом'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/Anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('чувак', 0.7908152937889099),\n",
       " ('джа', 0.7688435316085815),\n",
       " ('герло', 0.7603917121887207),\n",
       " ('hу', 0.7603676319122314),\n",
       " ('обломаться', 0.7556824684143066),\n",
       " ('блин', 0.7450451850891113),\n",
       " ('ганджа', 0.744154155254364),\n",
       " ('психиатор', 0.7407350540161133),\n",
       " ('короче', 0.7357670664787292),\n",
       " ('вишь', 0.7345012426376343)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('растаман')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
